# Testing Github Organization for Moxin-Models

[Placeholder for Brief Intro & Logo]

## Moxin-LLM

A new milestone in open large language model (LLM) development — designed to push the boundaries of performance and openness! 

[Placeholder for Schematic Diagram]

* [Moxin-LLM](https://github.com/moxin-org/Moxin-LLM) **True Transparency !**  full disclosure and reproducibility!
* [Technical Report](https://arxiv.org/pdf/2412.06845) 7B Fully Open Source Moxin-LLM – From Pretraining to GRPO-based Reinforcement Learning Enhancement
* [Huggingface Collection](https://huggingface.co/moxin-org) Huggingface Page for all released models. 

[Placeholder for Demo Video? / Performance table ?]

## Moxin-SD

locally running stable diffusion models on **edge device** - with flexible checkpoints and loRAs!

<img width="701" alt="image" src="https://github.com/user-attachments/assets/2d759c8d-eff8-4677-869a-bfdb1fa517ce" />


* [Ominix-SD](https://github.com/moxin-org/Ominix-SD.cpp) Significant inference speedups for SD.cpp
* [Technical Report](https://arxiv.org/pdf/2412.05781) Open-Source Acceleration of Stable-Diffusion.cpp Deployable on All Devices


## Moxin-TTS

[Placeholder for intro and Schematic Diagram]

* [Ominix TTS](https://github.com/moxin-org/Ominix-tts)  
* [Technical Report]

[Placeholder for Demo?]


## Moxin-Pruning & Compression (tbd)

Specialized pruning and quanlization for LLMs like DeepSeek MoE and Qwen MoE


...


<!--

**Here are some ideas to get you started:**

🙋‍♀️ A short introduction - what is your organization all about?
🌈 Contribution guidelines - how can the community get involved?
👩‍💻 Useful resources - where can the community find your docs? Is there anything else the community should know?
🍿 Fun facts - what does your team eat for breakfast?
🧙 Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
